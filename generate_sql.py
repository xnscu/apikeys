#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
API Keys åŠ¨æ€SQLç”Ÿæˆå™¨
è¯»å–apikeys.txtæ–‡ä»¶ï¼ŒåŠ¨æ€ç”ŸæˆSQLæ–‡ä»¶ï¼Œç„¶åä½¿ç”¨wrangleræ’å…¥D1æ•°æ®åº“
"""

import os
import sys
from datetime import datetime
import subprocess
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class APIKeySQLGenerator:
    def __init__(self, input_file='apikeys.txt', database_name='apikeys-pool'):
        self.input_file = input_file
        self.database_name = database_name
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.migrations_dir = 'migrations'

        # ç¡®ä¿migrationsç›®å½•å­˜åœ¨
        os.makedirs(self.migrations_dir, exist_ok=True)

    def read_apikeys(self):
        """åŠ¨æ€è¯»å–apikeys.txtæ–‡ä»¶"""
        api_keys = []

        if not os.path.exists(self.input_file):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.input_file}")
            return api_keys

        try:
            with open(self.input_file, 'r', encoding='utf-8') as file:
                for line_num, line in enumerate(file, 1):
                    line = line.strip()

                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if not line or line.startswith('#'):
                        continue

                    # è§£æ mail:key æ ¼å¼
                    if ':' not in line:
                        logger.warning(f"ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
                        continue

                    parts = line.split(':', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªå†’å·
                    if len(parts) != 2:
                        logger.warning(f"ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
                        continue

                    email = parts[0].strip()
                    api_key = parts[1].strip()

                    # åŸºæœ¬éªŒè¯
                    if not email or not api_key:
                        logger.warning(f"ç¬¬ {line_num} è¡Œæ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡: {line}")
                        continue

                    if '@' not in email:
                        logger.warning(f"ç¬¬ {line_num} è¡Œé‚®ç®±æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {email}")
                        continue

                    api_keys.append((email, api_key))

            logger.info(f"æˆåŠŸè¯»å– {len(api_keys)} æ¡APIå¯†é’¥è®°å½•")
            return api_keys

        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def generate_schema_sql(self):
        """è·³è¿‡ç”Ÿæˆè¡¨ç»“æ„SQL - ä½¿ç”¨ç°æœ‰çš„sql/schema.sql"""
        logger.info("è·³è¿‡ç”Ÿæˆè¡¨ç»“æ„æ–‡ä»¶ - ä½¿ç”¨ç°æœ‰çš„ sql/schema.sql")
        return "sql/schema.sql"

    def generate_insert_sql(self, api_keys):
        """åŠ¨æ€ç”ŸæˆINSERT SQLè¯­å¥ - é€‚é…ç°æœ‰è¡¨ç»“æ„"""
        if not api_keys:
            logger.warning("æ²¡æœ‰APIå¯†é’¥æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆæ’å…¥SQL")
            return None

        sql_lines = [
            "-- åŠ¨æ€ç”Ÿæˆçš„APIå¯†é’¥æ’å…¥SQL",
            "-- é€‚é…ç°æœ‰çš„api_keysè¡¨ç»“æ„",
            "-- ä½¿ç”¨INSERT OR REPLACEæ¥å¤„ç†é‡å¤çš„api_key",
            ""
        ]

        for email, api_key in api_keys:
            # è½¬ä¹‰å•å¼•å·
            email_escaped = email.replace("'", "''")
            api_key_escaped = api_key.replace("'", "''")

            # é€‚é…ç°æœ‰è¡¨ç»“æ„ï¼šapi_keyä¸ºå”¯ä¸€é”®ï¼Œgmail_emailå­˜å‚¨é‚®ç®±
            sql = f"INSERT OR REPLACE INTO api_keys (api_key, gmail_email, is_active, created_at, updated_at, total_requests, error_count) VALUES ('{api_key_escaped}', '{email_escaped}', 1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, 0, 0);"
            sql_lines.append(sql)

        insert_file = os.path.join(self.migrations_dir, f"insert_apikeys_{self.timestamp}.sql")
        with open(insert_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(sql_lines))

        logger.info(f"å·²ç”Ÿæˆæ’å…¥æ•°æ®æ–‡ä»¶: {insert_file}")
        return insert_file

    def generate_upsert_sql(self, api_keys):
        """ç”Ÿæˆç°ä»£åŒ–UPSERT SQL (ON CONFLICTè¯­æ³•) - é€‚é…ç°æœ‰è¡¨ç»“æ„"""
        if not api_keys:
            return None

        sql_lines = [
            "-- ä½¿ç”¨INSERT ... ON CONFLICTçš„ç°ä»£åŒ–è¯­æ³•",
            "-- é€‚é…ç°æœ‰çš„api_keysè¡¨ç»“æ„",
            "-- æ³¨æ„: éœ€è¦D1æ”¯æŒè¾ƒæ–°çš„SQLiteç‰ˆæœ¬",
            ""
        ]

        for email, api_key in api_keys:
            # è½¬ä¹‰å•å¼•å·
            email_escaped = email.replace("'", "''")
            api_key_escaped = api_key.replace("'", "''")

            sql = f"""INSERT INTO api_keys (api_key, gmail_email, is_active, created_at, updated_at, total_requests, error_count)
VALUES ('{api_key_escaped}', '{email_escaped}', 1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, 0, 0)
ON CONFLICT(api_key) DO UPDATE SET
    gmail_email = excluded.gmail_email,
    updated_at = CURRENT_TIMESTAMP,
    is_active = 1;"""

            sql_lines.append(sql)

        upsert_file = os.path.join(self.migrations_dir, f"upsert_apikeys_{self.timestamp}.sql")
        with open(upsert_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(sql_lines))

        logger.info(f"å·²ç”ŸæˆUPSERTæ•°æ®æ–‡ä»¶: {upsert_file}")
        return upsert_file

    def execute_wrangler_commands(self, schema_file, insert_file, auto_execute=False):
        """ç”Ÿæˆå¹¶å¯é€‰æ‰§è¡Œwranglerå‘½ä»¤"""
        commands = [
            f"wrangler d1 execute {self.database_name} --file={schema_file}",
            f"wrangler d1 execute {self.database_name} --file={insert_file}"
        ]

        # ç”Ÿæˆå‘½ä»¤æ–‡ä»¶
        commands_content = f"""# Cloudflare D1 æ•°æ®åº“æ“ä½œå‘½ä»¤

## 1. è¡¨ç»“æ„å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º
# {commands[0]}  # ä¸éœ€è¦æ‰§è¡Œï¼Œä½¿ç”¨ç°æœ‰çš„sql/schema.sql

## 2. æ’å…¥APIå¯†é’¥æ•°æ®
{commands[1]}

## 3. éªŒè¯æ•°æ®
wrangler d1 execute {self.database_name} --command="SELECT COUNT(*) as total FROM api_keys;"
wrangler d1 execute {self.database_name} --command="SELECT api_key, gmail_email, is_active, created_at FROM api_keys ORDER BY created_at DESC LIMIT 10;"

## 4. æŸ¥è¯¢ç‰¹å®šé‚®ç®±
wrangler d1 execute {self.database_name} --command="SELECT * FROM api_keys WHERE gmail_email LIKE '%gmail.com';"

## 5. æŸ¥è¯¢æ¿€æ´»çŠ¶æ€çš„API Keys
wrangler d1 execute {self.database_name} --command="SELECT * FROM api_keys WHERE is_active = 1;"

## 6. å¦‚æœéœ€è¦æ¸…ç©ºè¡¨é‡æ–°å¯¼å…¥
wrangler d1 execute {self.database_name} --command="DELETE FROM api_keys;"

## æ³¨æ„äº‹é¡¹:
# - è¡¨ç»“æ„å·²å­˜åœ¨äºsql/schema.sqlï¼Œæ— éœ€é‡æ–°åˆ›å»º
# - ä½¿ç”¨api_keyä½œä¸ºå”¯ä¸€é”®ï¼Œé‡å¤çš„api_keyä¼šè¢«æ›´æ–°
# - gmail_emailå­—æ®µå­˜å‚¨é‚®ç®±åœ°å€
# - is_activeé»˜è®¤ä¸º1ï¼ˆæ¿€æ´»çŠ¶æ€ï¼‰
# - å½“å‰é…ç½®çš„æ•°æ®åº“åç§°æ˜¯: {self.database_name}
"""

        commands_file = os.path.join(self.migrations_dir, f"wrangler_commands_{self.timestamp}.txt")
        with open(commands_file, 'w', encoding='utf-8') as f:
            f.write(commands_content)

        logger.info(f"å·²ç”Ÿæˆwranglerå‘½ä»¤æ–‡ä»¶: {commands_file}")

        # å¦‚æœå¯ç”¨è‡ªåŠ¨æ‰§è¡Œ
        if auto_execute:
            logger.info("å¼€å§‹è‡ªåŠ¨æ‰§è¡Œwranglerå‘½ä»¤...")
            for i, cmd in enumerate(commands, 1):
                logger.info(f"æ‰§è¡Œå‘½ä»¤ {i}: {cmd}")
                try:
                    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                    if result.returncode == 0:
                        logger.info(f"å‘½ä»¤ {i} æ‰§è¡ŒæˆåŠŸ")
                        if result.stdout:
                            logger.info(f"è¾“å‡º: {result.stdout}")
                    else:
                        logger.error(f"å‘½ä»¤ {i} æ‰§è¡Œå¤±è´¥: {result.stderr}")
                        return False
                except Exception as e:
                    logger.error(f"æ‰§è¡Œå‘½ä»¤ {i} æ—¶å‡ºé”™: {e}")
                    return False

            logger.info("æ‰€æœ‰wranglerå‘½ä»¤æ‰§è¡Œå®Œæˆ")
            return True

        return commands_file

    def run(self, auto_execute=False):
        """è¿è¡Œå®Œæ•´çš„æµç¨‹"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {self.input_file}")

        # 1. è¯»å–APIå¯†é’¥æ•°æ®
        api_keys = self.read_apikeys()
        if not api_keys:
            logger.error("æ²¡æœ‰è¯»å–åˆ°æœ‰æ•ˆçš„APIå¯†é’¥æ•°æ®")
            return False

        # 2. ç”ŸæˆSQLæ–‡ä»¶
        schema_file = self.generate_schema_sql()
        insert_file = self.generate_insert_sql(api_keys)
        upsert_file = self.generate_upsert_sql(api_keys)

        if not insert_file:
            logger.error("ç”Ÿæˆæ’å…¥SQLæ–‡ä»¶å¤±è´¥")
            return False

        # 3. å¤„ç†wranglerå‘½ä»¤
        result = self.execute_wrangler_commands(schema_file, insert_file, auto_execute)

        # 4. è¾“å‡ºç»“æœ
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š å…±å¤„ç† {len(api_keys)} æ¡APIå¯†é’¥è®°å½•")
        print(f"ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  - è¡¨ç»“æ„: {schema_file}")
        print(f"  - æ’å…¥æ•°æ®: {insert_file}")
        print(f"  - UPSERTæ•°æ®: {upsert_file}")

        if not auto_execute:
            print(f"  - å‘½ä»¤è¯´æ˜: {result}")
            print(f"\nğŸš€ æ¥ä¸‹æ¥æ‰‹åŠ¨æ‰§è¡Œå‘½ä»¤:")
            print(f"wrangler d1 execute {self.database_name} --file={schema_file}")
            print(f"wrangler d1 execute {self.database_name} --file={insert_file}")
        else:
            print(f"âœ… æ•°æ®å·²è‡ªåŠ¨å¯¼å…¥åˆ°æ•°æ®åº“: {self.database_name}")

        return True

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    input_file = 'apikeys.txt'
    database_name = 'apikeys-pool'
    auto_execute = False

    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    if len(sys.argv) > 2:
        database_name = sys.argv[2]
    if len(sys.argv) > 3:
        auto_execute = sys.argv[3].lower() in ['true', '1', 'yes', 'auto']

    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = APIKeySQLGenerator(input_file, database_name)
    success = generator.run(auto_execute)

    if not success:
        sys.exit(1)

    print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print(f"python {sys.argv[0]} [è¾“å…¥æ–‡ä»¶] [æ•°æ®åº“å] [è‡ªåŠ¨æ‰§è¡Œ]")
    print(f"ç¤ºä¾‹: python {sys.argv[0]} apikeys.txt apikeys-pool true")

if __name__ == "__main__":
    main()
